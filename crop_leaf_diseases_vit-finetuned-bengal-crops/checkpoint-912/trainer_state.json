{
  "best_global_step": 912,
  "best_metric": 0.9059789522377704,
  "best_model_checkpoint": "crop_leaf_diseases_vit-finetuned-bengal-crops/checkpoint-912",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 912,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03289473684210526,
      "grad_norm": 12.609896659851074,
      "learning_rate": 4.891304347826087e-06,
      "loss": 4.8549,
      "step": 10
    },
    {
      "epoch": 0.06578947368421052,
      "grad_norm": 11.079723358154297,
      "learning_rate": 1.032608695652174e-05,
      "loss": 4.5386,
      "step": 20
    },
    {
      "epoch": 0.09868421052631579,
      "grad_norm": 9.725881576538086,
      "learning_rate": 1.5760869565217393e-05,
      "loss": 3.9546,
      "step": 30
    },
    {
      "epoch": 0.13157894736842105,
      "grad_norm": 8.715989112854004,
      "learning_rate": 2.1195652173913045e-05,
      "loss": 3.3685,
      "step": 40
    },
    {
      "epoch": 0.16447368421052633,
      "grad_norm": 8.663911819458008,
      "learning_rate": 2.66304347826087e-05,
      "loss": 2.8831,
      "step": 50
    },
    {
      "epoch": 0.19736842105263158,
      "grad_norm": 7.847987174987793,
      "learning_rate": 3.2065217391304345e-05,
      "loss": 2.4522,
      "step": 60
    },
    {
      "epoch": 0.23026315789473684,
      "grad_norm": 7.690943717956543,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.9855,
      "step": 70
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 7.396684169769287,
      "learning_rate": 4.2934782608695655e-05,
      "loss": 1.7484,
      "step": 80
    },
    {
      "epoch": 0.29605263157894735,
      "grad_norm": 9.15156364440918,
      "learning_rate": 4.836956521739131e-05,
      "loss": 1.5386,
      "step": 90
    },
    {
      "epoch": 0.32894736842105265,
      "grad_norm": 6.559525966644287,
      "learning_rate": 4.957317073170732e-05,
      "loss": 1.3707,
      "step": 100
    },
    {
      "epoch": 0.3618421052631579,
      "grad_norm": 7.631489276885986,
      "learning_rate": 4.8963414634146345e-05,
      "loss": 1.1958,
      "step": 110
    },
    {
      "epoch": 0.39473684210526316,
      "grad_norm": 7.153675079345703,
      "learning_rate": 4.8353658536585366e-05,
      "loss": 1.0835,
      "step": 120
    },
    {
      "epoch": 0.4276315789473684,
      "grad_norm": 5.956125736236572,
      "learning_rate": 4.774390243902439e-05,
      "loss": 0.9975,
      "step": 130
    },
    {
      "epoch": 0.4605263157894737,
      "grad_norm": 6.634929656982422,
      "learning_rate": 4.7134146341463415e-05,
      "loss": 0.9107,
      "step": 140
    },
    {
      "epoch": 0.4934210526315789,
      "grad_norm": 6.914709568023682,
      "learning_rate": 4.652439024390244e-05,
      "loss": 0.8397,
      "step": 150
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 7.089514255523682,
      "learning_rate": 4.5914634146341464e-05,
      "loss": 0.7971,
      "step": 160
    },
    {
      "epoch": 0.5592105263157895,
      "grad_norm": 5.7283034324646,
      "learning_rate": 4.530487804878049e-05,
      "loss": 0.7599,
      "step": 170
    },
    {
      "epoch": 0.5921052631578947,
      "grad_norm": 6.263228893280029,
      "learning_rate": 4.4695121951219513e-05,
      "loss": 0.7433,
      "step": 180
    },
    {
      "epoch": 0.625,
      "grad_norm": 6.4065632820129395,
      "learning_rate": 4.408536585365854e-05,
      "loss": 0.7027,
      "step": 190
    },
    {
      "epoch": 0.6578947368421053,
      "grad_norm": 6.182488918304443,
      "learning_rate": 4.347560975609756e-05,
      "loss": 0.6459,
      "step": 200
    },
    {
      "epoch": 0.6907894736842105,
      "grad_norm": 6.011292457580566,
      "learning_rate": 4.2865853658536584e-05,
      "loss": 0.6292,
      "step": 210
    },
    {
      "epoch": 0.7236842105263158,
      "grad_norm": 6.395169734954834,
      "learning_rate": 4.225609756097561e-05,
      "loss": 0.6094,
      "step": 220
    },
    {
      "epoch": 0.756578947368421,
      "grad_norm": 6.187236785888672,
      "learning_rate": 4.164634146341463e-05,
      "loss": 0.5727,
      "step": 230
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 6.153586387634277,
      "learning_rate": 4.103658536585366e-05,
      "loss": 0.5931,
      "step": 240
    },
    {
      "epoch": 0.8223684210526315,
      "grad_norm": 5.3091864585876465,
      "learning_rate": 4.042682926829269e-05,
      "loss": 0.557,
      "step": 250
    },
    {
      "epoch": 0.8552631578947368,
      "grad_norm": 5.133683204650879,
      "learning_rate": 3.981707317073171e-05,
      "loss": 0.5221,
      "step": 260
    },
    {
      "epoch": 0.8881578947368421,
      "grad_norm": 5.8776936531066895,
      "learning_rate": 3.920731707317074e-05,
      "loss": 0.5099,
      "step": 270
    },
    {
      "epoch": 0.9210526315789473,
      "grad_norm": 6.070863723754883,
      "learning_rate": 3.859756097560976e-05,
      "loss": 0.5432,
      "step": 280
    },
    {
      "epoch": 0.9539473684210527,
      "grad_norm": 6.570591926574707,
      "learning_rate": 3.798780487804878e-05,
      "loss": 0.5332,
      "step": 290
    },
    {
      "epoch": 0.9868421052631579,
      "grad_norm": 5.05946159362793,
      "learning_rate": 3.737804878048781e-05,
      "loss": 0.4845,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.845611194633977,
      "eval_loss": 0.4700026214122772,
      "eval_runtime": 196.1702,
      "eval_samples_per_second": 44.079,
      "eval_steps_per_second": 0.693,
      "step": 304
    },
    {
      "epoch": 1.019736842105263,
      "grad_norm": 6.220460414886475,
      "learning_rate": 3.676829268292683e-05,
      "loss": 0.472,
      "step": 310
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 6.301569938659668,
      "learning_rate": 3.615853658536586e-05,
      "loss": 0.4654,
      "step": 320
    },
    {
      "epoch": 1.0855263157894737,
      "grad_norm": 6.8382439613342285,
      "learning_rate": 3.554878048780488e-05,
      "loss": 0.4433,
      "step": 330
    },
    {
      "epoch": 1.118421052631579,
      "grad_norm": 5.092415809631348,
      "learning_rate": 3.49390243902439e-05,
      "loss": 0.4364,
      "step": 340
    },
    {
      "epoch": 1.1513157894736843,
      "grad_norm": 5.349725723266602,
      "learning_rate": 3.4329268292682934e-05,
      "loss": 0.4152,
      "step": 350
    },
    {
      "epoch": 1.1842105263157894,
      "grad_norm": 5.844316482543945,
      "learning_rate": 3.3719512195121955e-05,
      "loss": 0.4117,
      "step": 360
    },
    {
      "epoch": 1.2171052631578947,
      "grad_norm": 5.833661079406738,
      "learning_rate": 3.3109756097560976e-05,
      "loss": 0.412,
      "step": 370
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.874246120452881,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.4091,
      "step": 380
    },
    {
      "epoch": 1.2828947368421053,
      "grad_norm": 5.173893928527832,
      "learning_rate": 3.1890243902439025e-05,
      "loss": 0.4068,
      "step": 390
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 5.450744152069092,
      "learning_rate": 3.128048780487805e-05,
      "loss": 0.3985,
      "step": 400
    },
    {
      "epoch": 1.3486842105263157,
      "grad_norm": 4.862730503082275,
      "learning_rate": 3.0670731707317074e-05,
      "loss": 0.381,
      "step": 410
    },
    {
      "epoch": 1.381578947368421,
      "grad_norm": 5.633747100830078,
      "learning_rate": 3.00609756097561e-05,
      "loss": 0.4075,
      "step": 420
    },
    {
      "epoch": 1.4144736842105263,
      "grad_norm": 5.263155937194824,
      "learning_rate": 2.9451219512195123e-05,
      "loss": 0.3965,
      "step": 430
    },
    {
      "epoch": 1.4473684210526316,
      "grad_norm": 5.935688495635986,
      "learning_rate": 2.8841463414634144e-05,
      "loss": 0.3801,
      "step": 440
    },
    {
      "epoch": 1.4802631578947367,
      "grad_norm": 4.445173263549805,
      "learning_rate": 2.823170731707317e-05,
      "loss": 0.3602,
      "step": 450
    },
    {
      "epoch": 1.513157894736842,
      "grad_norm": 5.65668249130249,
      "learning_rate": 2.76219512195122e-05,
      "loss": 0.3563,
      "step": 460
    },
    {
      "epoch": 1.5460526315789473,
      "grad_norm": 6.041345119476318,
      "learning_rate": 2.701219512195122e-05,
      "loss": 0.3437,
      "step": 470
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 4.925783157348633,
      "learning_rate": 2.6402439024390246e-05,
      "loss": 0.3504,
      "step": 480
    },
    {
      "epoch": 1.611842105263158,
      "grad_norm": 5.461068630218506,
      "learning_rate": 2.579268292682927e-05,
      "loss": 0.3687,
      "step": 490
    },
    {
      "epoch": 1.6447368421052633,
      "grad_norm": 4.089183807373047,
      "learning_rate": 2.5182926829268295e-05,
      "loss": 0.3376,
      "step": 500
    },
    {
      "epoch": 1.6776315789473686,
      "grad_norm": 4.742371082305908,
      "learning_rate": 2.457317073170732e-05,
      "loss": 0.3509,
      "step": 510
    },
    {
      "epoch": 1.7105263157894737,
      "grad_norm": 5.486568450927734,
      "learning_rate": 2.396341463414634e-05,
      "loss": 0.3334,
      "step": 520
    },
    {
      "epoch": 1.743421052631579,
      "grad_norm": 4.765944004058838,
      "learning_rate": 2.335365853658537e-05,
      "loss": 0.3328,
      "step": 530
    },
    {
      "epoch": 1.776315789473684,
      "grad_norm": 5.555777072906494,
      "learning_rate": 2.2743902439024393e-05,
      "loss": 0.3583,
      "step": 540
    },
    {
      "epoch": 1.8092105263157894,
      "grad_norm": 4.4416890144348145,
      "learning_rate": 2.2134146341463417e-05,
      "loss": 0.3389,
      "step": 550
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 4.920660018920898,
      "learning_rate": 2.152439024390244e-05,
      "loss": 0.3416,
      "step": 560
    },
    {
      "epoch": 1.875,
      "grad_norm": 4.725063323974609,
      "learning_rate": 2.0914634146341463e-05,
      "loss": 0.2961,
      "step": 570
    },
    {
      "epoch": 1.9078947368421053,
      "grad_norm": 4.915677547454834,
      "learning_rate": 2.030487804878049e-05,
      "loss": 0.3317,
      "step": 580
    },
    {
      "epoch": 1.9407894736842106,
      "grad_norm": 4.577563762664795,
      "learning_rate": 1.9695121951219516e-05,
      "loss": 0.3001,
      "step": 590
    },
    {
      "epoch": 1.973684210526316,
      "grad_norm": 4.992429733276367,
      "learning_rate": 1.9085365853658537e-05,
      "loss": 0.3312,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.893257777263791,
      "eval_loss": 0.31279754638671875,
      "eval_runtime": 182.62,
      "eval_samples_per_second": 47.35,
      "eval_steps_per_second": 0.745,
      "step": 608
    },
    {
      "epoch": 2.0065789473684212,
      "grad_norm": 4.597548961639404,
      "learning_rate": 1.847560975609756e-05,
      "loss": 0.3238,
      "step": 610
    },
    {
      "epoch": 2.039473684210526,
      "grad_norm": 5.09596061706543,
      "learning_rate": 1.7865853658536586e-05,
      "loss": 0.2949,
      "step": 620
    },
    {
      "epoch": 2.0723684210526314,
      "grad_norm": 5.218151092529297,
      "learning_rate": 1.725609756097561e-05,
      "loss": 0.304,
      "step": 630
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 5.702626705169678,
      "learning_rate": 1.6646341463414635e-05,
      "loss": 0.2833,
      "step": 640
    },
    {
      "epoch": 2.138157894736842,
      "grad_norm": 4.4345197677612305,
      "learning_rate": 1.603658536585366e-05,
      "loss": 0.2767,
      "step": 650
    },
    {
      "epoch": 2.1710526315789473,
      "grad_norm": 4.685500144958496,
      "learning_rate": 1.5426829268292684e-05,
      "loss": 0.2853,
      "step": 660
    },
    {
      "epoch": 2.2039473684210527,
      "grad_norm": 4.667990684509277,
      "learning_rate": 1.4817073170731707e-05,
      "loss": 0.2932,
      "step": 670
    },
    {
      "epoch": 2.236842105263158,
      "grad_norm": 2.9601855278015137,
      "learning_rate": 1.4207317073170731e-05,
      "loss": 0.2832,
      "step": 680
    },
    {
      "epoch": 2.2697368421052633,
      "grad_norm": 4.5052809715271,
      "learning_rate": 1.3597560975609757e-05,
      "loss": 0.2786,
      "step": 690
    },
    {
      "epoch": 2.3026315789473686,
      "grad_norm": 4.374846935272217,
      "learning_rate": 1.2987804878048782e-05,
      "loss": 0.2578,
      "step": 700
    },
    {
      "epoch": 2.3355263157894735,
      "grad_norm": 5.334469318389893,
      "learning_rate": 1.2378048780487805e-05,
      "loss": 0.2792,
      "step": 710
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 5.409732818603516,
      "learning_rate": 1.176829268292683e-05,
      "loss": 0.2627,
      "step": 720
    },
    {
      "epoch": 2.401315789473684,
      "grad_norm": 4.315840721130371,
      "learning_rate": 1.1158536585365854e-05,
      "loss": 0.2856,
      "step": 730
    },
    {
      "epoch": 2.4342105263157894,
      "grad_norm": 4.167389869689941,
      "learning_rate": 1.0548780487804878e-05,
      "loss": 0.2884,
      "step": 740
    },
    {
      "epoch": 2.4671052631578947,
      "grad_norm": 4.083138942718506,
      "learning_rate": 9.939024390243903e-06,
      "loss": 0.2802,
      "step": 750
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.203776836395264,
      "learning_rate": 9.329268292682927e-06,
      "loss": 0.2765,
      "step": 760
    },
    {
      "epoch": 2.5328947368421053,
      "grad_norm": 4.173173904418945,
      "learning_rate": 8.71951219512195e-06,
      "loss": 0.2524,
      "step": 770
    },
    {
      "epoch": 2.5657894736842106,
      "grad_norm": 4.862539768218994,
      "learning_rate": 8.109756097560977e-06,
      "loss": 0.246,
      "step": 780
    },
    {
      "epoch": 2.598684210526316,
      "grad_norm": 4.1270527839660645,
      "learning_rate": 7.5e-06,
      "loss": 0.2602,
      "step": 790
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 3.998701572418213,
      "learning_rate": 6.8902439024390256e-06,
      "loss": 0.2528,
      "step": 800
    },
    {
      "epoch": 2.6644736842105265,
      "grad_norm": 3.213179588317871,
      "learning_rate": 6.280487804878049e-06,
      "loss": 0.2485,
      "step": 810
    },
    {
      "epoch": 2.6973684210526314,
      "grad_norm": 4.416635990142822,
      "learning_rate": 5.670731707317074e-06,
      "loss": 0.2533,
      "step": 820
    },
    {
      "epoch": 2.7302631578947367,
      "grad_norm": 4.816220283508301,
      "learning_rate": 5.060975609756098e-06,
      "loss": 0.2621,
      "step": 830
    },
    {
      "epoch": 2.763157894736842,
      "grad_norm": 4.40414571762085,
      "learning_rate": 4.451219512195122e-06,
      "loss": 0.2573,
      "step": 840
    },
    {
      "epoch": 2.7960526315789473,
      "grad_norm": 4.738774299621582,
      "learning_rate": 3.8414634146341465e-06,
      "loss": 0.2418,
      "step": 850
    },
    {
      "epoch": 2.8289473684210527,
      "grad_norm": 4.229903697967529,
      "learning_rate": 3.231707317073171e-06,
      "loss": 0.229,
      "step": 860
    },
    {
      "epoch": 2.861842105263158,
      "grad_norm": 3.694932222366333,
      "learning_rate": 2.621951219512195e-06,
      "loss": 0.2628,
      "step": 870
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 4.191348075866699,
      "learning_rate": 2.0121951219512197e-06,
      "loss": 0.2392,
      "step": 880
    },
    {
      "epoch": 2.9276315789473686,
      "grad_norm": 3.2884395122528076,
      "learning_rate": 1.402439024390244e-06,
      "loss": 0.2419,
      "step": 890
    },
    {
      "epoch": 2.9605263157894735,
      "grad_norm": 4.153783321380615,
      "learning_rate": 7.926829268292684e-07,
      "loss": 0.2578,
      "step": 900
    },
    {
      "epoch": 2.9934210526315788,
      "grad_norm": 4.184357166290283,
      "learning_rate": 1.829268292682927e-07,
      "loss": 0.2491,
      "step": 910
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9059789522377704,
      "eval_loss": 0.27027738094329834,
      "eval_runtime": 180.3106,
      "eval_samples_per_second": 47.956,
      "eval_steps_per_second": 0.754,
      "step": 912
    }
  ],
  "logging_steps": 10,
  "max_steps": 912,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1686683146032742e+18,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
